{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Retail Banking: Data Ingestion, Cleaning, and EDA\n",
    "\n",
    "This notebook ingests the provided banking transactions dataset, performs systematic data cleaning, and conducts exploratory data analysis (EDA) following best practices. The goal is to prepare high-quality data and surface insights that will support RFM-based customer segmentation in subsequent steps.\n",
    "\n",
    "### Objectives\n",
    "- Load dataset and validate schema against project instructions\n",
    "- Clean types, missing values, duplicates, and inconsistent categories\n",
    "- Assess outliers and data quality\n",
    "- Explore univariate and bivariate distributions\n",
    "- Summarize customer behavior and transaction patterns\n",
    "- Prepare and export cleaned data and intermediate artifacts\n",
    "\n",
    "> Dataset path: `data/bank_data_C.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and configuration\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting aesthetics\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (10, 6),\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "})\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parents[0] if (Path.cwd().name == \"notebooks\") else Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_PATH = DATA_DIR / \"bank_data_C.csv\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "RAW_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary (from instructions)\n",
    "- TransactionID: Unique transaction ID\n",
    "- CustomerID: Unique customer ID\n",
    "- CustomerDOB: Date of birth\n",
    "- CustGender: Customer gender\n",
    "- CustLocation: Customer location\n",
    "- CustAccountBalance: Current account balance\n",
    "- TransactionDate: Date of transaction\n",
    "- TransactionTime: Timestamp of transaction\n",
    "- TransactionAmount: Value of transaction\n",
    "\n",
    "We'll validate these fields after loading the CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "assert RAW_PATH.exists(), f\"Expected CSV not found at {RAW_PATH}\"\n",
    "\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "print(df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial inspection\n",
    "info_buf = []\n",
    "df_info = df.dtypes.astype(str).rename(\"dtype\").to_frame()\n",
    "df_info[\"non_null\"] = df.notnull().sum()\n",
    "df_info[\"null\"] = df.isnull().sum()\n",
    "df_info[\"unique\"] = df.nunique()\n",
    "df_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning plan\n",
    "We'll apply the following steps:\n",
    "1. Fix data types for dates/times and numeric fields\n",
    "2. Standardize categorical values (e.g., gender casing)\n",
    "3. Remove exact duplicate rows, then deduplicate per `TransactionID`\n",
    "4. Handle missing values with context-aware strategies\n",
    "5. Identify and treat outliers in `TransactionAmount` and `CustAccountBalance`\n",
    "6. Validate referential logic (e.g., non-negative amounts, reasonable DOB)\n",
    "7. Create clean dataset snapshot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parsed date/time columns first so later temporal analyses work reliably. Any unparsable values are set to missing (`NaT`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric conversions\n",
    "for col in [\"CustAccountBalance\", \"TransactionAmount\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\"Numeric conversions complete\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted monetary fields to numeric, coercing invalid strings to `NaN`. This ensures stats/plots work without errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical standardization\n",
    "if \"CustGender\" in df.columns:\n",
    "    df[\"CustGender\"] = (\n",
    "        df[\"CustGender\"].astype(str).str.strip().str.title().replace({\"Nan\": np.nan})\n",
    "    )\n",
    "\n",
    "if \"CustLocation\" in df.columns:\n",
    "    df[\"CustLocation\"] = df[\"CustLocation\"].astype(str).str.strip().replace({\"nan\": np.nan, \"\": np.nan})\n",
    "\"Categorical cleaning complete\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender and location values are standardized to consistent casing and trimmed. Obvious placeholders like empty strings are treated as missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date and time columns\n",
    "for col in [\"CustomerDOB\", \"TransactionDate\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# Parse TransactionTime if present\n",
    "if \"TransactionTime\" in df.columns and not np.issubdtype(df[\"TransactionTime\"].dtype, np.datetime64):\n",
    "    try:\n",
    "        df[\"TransactionTime\"] = pd.to_datetime(df[\"TransactionTime\"], errors=\"coerce\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\"Date/time parsing complete\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplication\n",
    "before = len(df)\n",
    "# Remove exact duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Ensure unique TransactionID if present\n",
    "if \"TransactionID\" in df.columns:\n",
    "    dup_tx = df[\"TransactionID\"].duplicated(keep=False)\n",
    "    print({\"duplicate_transaction_ids\": int(dup_tx.sum())})\n",
    "    df = df.drop_duplicates(subset=[\"TransactionID\"], keep=\"first\")\n",
    "\n",
    "after = len(df)\n",
    "{\"removed_duplicates\": before - after, \"rows_remaining\": after}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values overview\n",
    "missing = df.isnull().mean().sort_values(ascending=False)\n",
    "missing = missing[missing > 0]\n",
    "missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value handling strategy\n",
    "- `CustomerDOB`: leave missing if unparseable; optional imputation later for modeling\n",
    "- `CustGender`, `CustLocation`: leave missing; consider 'Unknown' label if needed in dashboards\n",
    "- `CustAccountBalance`, `TransactionAmount`: numeric imputation not advised without domain context; leave missing or drop only when required for specific analyses\n",
    "- `TransactionDate`/`Time`: records without a valid date are not usable for temporal analyses and will be dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply minimal, conservative row filtering for critical fields\n",
    "rows_before = len(df)\n",
    "\n",
    "# Drop rows with no valid TransactionDate\n",
    "df = df[~df[\"TransactionDate\"].isna()] if \"TransactionDate\" in df.columns else df\n",
    "\n",
    "# Ensure TransactionAmount exists for transaction-level EDA\n",
    "df = df[~df[\"TransactionAmount\"].isna()] if \"TransactionAmount\" in df.columns else df\n",
    "\n",
    "rows_after = len(df)\n",
    "{\"dropped_rows\": rows_before - rows_after, \"rows_remaining\": rows_after}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection (univariate)\n",
    "outlier_summary = {}\n",
    "for col in [\"TransactionAmount\", \"CustAccountBalance\"]:\n",
    "    if col in df.columns:\n",
    "        series = df[col].dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "        q1, q3 = series.quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        outlier_summary[col] = {\n",
    "            \"iqr_lower\": float(lower),\n",
    "            \"iqr_upper\": float(upper),\n",
    "            \"num_lower\": int((series < lower).sum()),\n",
    "            \"num_upper\": int((series > upper).sum()),\n",
    "        }\n",
    "outlier_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier treatment approach\n",
    "We'll apply winsorization caps for visualization stability but retain raw values in a separate copy for reference. This balances robustness in charts with data fidelity for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema overview (concise)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " next step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capped copy for EDA visuals\n",
    "eda = df.copy()\n",
    "for col in [\"TransactionAmount\", \"CustAccountBalance\"]:\n",
    "    if col in eda.columns:\n",
    "        lower, upper = eda[col].quantile([0.01, 0.99])\n",
    "        eda[col] = eda[col].clip(lower=lower, upper=upper)\n",
    "\n",
    "\"Capped columns for EDA visuals\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate distributions (numeric)\n",
    "num_cols = [c for c in [\"TransactionAmount\", \"CustAccountBalance\"] if c in eda.columns]\n",
    "for col in num_cols:\n",
    "    sns.histplot(eda[col].dropna(), kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate distributions (categorical)\n",
    "cat_cols = [c for c in [\"CustGender\", \"CustLocation\"] if c in eda.columns]\n",
    "for col in cat_cols:\n",
    "    order = eda[col].value_counts(dropna=False).index\n",
    "    sns.countplot(y=col, data=eda, order=order)\n",
    "    plt.title(f\"Counts of {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal patterns if TransactionDate present\n",
    "if \"TransactionDate\" in eda.columns:\n",
    "    eda[\"TransactionDate\"] = pd.to_datetime(eda[\"TransactionDate\"])  # idempotent\n",
    "    eda[\"YearMonth\"] = eda[\"TransactionDate\"].dt.to_period(\"M\").astype(str)\n",
    "    monthly = eda.groupby(\"YearMonth\")[\"TransactionAmount\"].agg([\"count\", \"sum\"]).reset_index()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    sns.lineplot(data=monthly, x=\"YearMonth\", y=\"count\", ax=ax1, label=\"Transactions Count\")\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.lineplot(data=monthly, x=\"YearMonth\", y=\"sum\", ax=ax2, color=\"orange\", label=\"Total Amount\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    plt.title(\"Monthly Transactions and Amount\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer-level summaries\n",
    "if \"CustomerID\" in eda.columns:\n",
    "    customer_tx = (\n",
    "        eda.groupby(\"CustomerID\").agg(\n",
    "            num_transactions=(\"TransactionID\", \"nunique\") if \"TransactionID\" in eda.columns else (\"TransactionAmount\", \"count\"),\n",
    "            total_amount=(\"TransactionAmount\", \"sum\"),\n",
    "            avg_amount=(\"TransactionAmount\", \"mean\"),\n",
    "            last_tx_date=(\"TransactionDate\", \"max\") if \"TransactionDate\" in eda.columns else (\"TransactionAmount\", \"idxmax\"),\n",
    "        )\n",
    "    )\n",
    "    customer_tx = customer_tx.sort_values(\"total_amount\", ascending=False)\n",
    "    customer_tx.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
